{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbofan Engine Degradation Simulation Dataset with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/johnmollas/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/johnmollas/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/johnmollas/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/johnmollas/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/johnmollas/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/johnmollas/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from load_dataset import Load_Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, TimeDistributed, RepeatVector,Flatten, Input, Dropout, LSTM, concatenate, Reshape, Conv1D, GlobalMaxPool1D\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from wandb import magic #For visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load and clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fm, feature_names = Load_Dataset.load_data_turbofan(False)\n",
    "\n",
    "fm1_train = fm['FaultMode1']['df_train']\n",
    "fm1_train_target = fm1_train['RUL'].values\n",
    "fm1_test= fm['FaultMode1']['df_test']\n",
    "fm1_test_target = fm1_test['RUL'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dropping some unecessary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_train = fm1_train.drop(columns=['t', 'os_1', 'os_2', 'os_3', 's_01', 's_05', 's_06', 's_10', 's_16', 's_18', 's_19', 's_22', 's_23', 's_24', 's_25', 's_26'])\n",
    "LSTM_test = fm1_test.drop(columns=['t', 'os_1', 'os_2', 'os_3', 's_01', 's_05', 's_06', 's_10', 's_16', 's_18', 's_19', 's_22', 's_23', 's_24', 's_25', 's_26'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We collect the different units, in order to the next steps to create time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_units = set(LSTM_train['u'].values)\n",
    "test_units = set(LSTM_test['u'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are scaling our data per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_scale = ['s_02', 's_03', 's_04', 's_07', 's_08', 's_09', 's_11', 's_12',\n",
    "            's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n",
    "scalers = {}\n",
    "for column in to_scale:\n",
    "    scaler = MinMaxScaler(feature_range=(0.1,1.1))\n",
    "    LSTM_train[column] = scaler.fit_transform(LSTM_train[column].values.reshape(-1,1))\n",
    "    LSTM_test[column] = scaler.transform(LSTM_test[column].values.reshape(-1,1))\n",
    "    scalers[column] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create time windows with a specific size. In this example, we create time windows of 50 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_scalers = {}\n",
    "window = 50\n",
    "temp_LSTM_x_train = []\n",
    "LSTM_y_train = []\n",
    "for unit in train_units:\n",
    "    temp_unit = LSTM_train[LSTM_train['u']==unit].drop(columns=['u','RUL']).values\n",
    "    temp_unit_RUL = LSTM_train[LSTM_train['u']==unit]['RUL'].values\n",
    "    \n",
    "    for i in range(len(temp_unit) - window + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = []\n",
    "        for j in range(window):\n",
    "            temp_instance.append(temp_unit[i+j])\n",
    "        temp_LSTM_x_train.append(np.array(temp_instance))\n",
    "        LSTM_y_train.append(temp_unit_RUL[i+window-1])\n",
    "LSTM_y_train = np.array(LSTM_y_train)\n",
    "LSTM_x_train = np.array(temp_LSTM_x_train)\n",
    "\n",
    "temp_LSTM_x_test = []\n",
    "LSTM_y_test = []\n",
    "for unit in test_units:\n",
    "    temp_unit = LSTM_test[LSTM_test['u']==unit].drop(columns=['u','RUL']).values\n",
    "    temp_unit_RUL = LSTM_test[LSTM_test['u']==unit]['RUL'].values\n",
    "        \n",
    "    for i in range(len(temp_unit) - window + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = []\n",
    "        for j in range(window):\n",
    "            temp_instance.append(temp_unit[i+j])\n",
    "        temp_LSTM_x_test.append(np.array(temp_instance))\n",
    "        LSTM_y_test.append(temp_unit_RUL[i+window-1])\n",
    "LSTM_y_test = np.array(LSTM_y_test)\n",
    "LSTM_x_test = np.array(temp_LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many train, test instances we have. These are changing regarding the time window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15731, 50, 14), (8255, 50, 14), (15731,), (8255,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_x_train.shape, LSTM_x_test.shape, LSTM_y_train.shape, LSTM_y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we scale our target data, in order to train our models faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_LSTM_y_train = [[i] for i in LSTM_y_train]\n",
    "temp_LSTM_y_test = [[i] for i in LSTM_y_test]\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaler.fit(temp_LSTM_y_train)\n",
    "temp_LSTM_y_train = target_scaler.transform(temp_LSTM_y_train)\n",
    "temp_LSTM_y_test = target_scaler.transform(temp_LSTM_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We need a rmse loss function too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build our predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = fm1_train.columns\n",
    "encoder_input = Input(shape=(LSTM_x_train[0].shape))\n",
    "\n",
    "encoder_x = LSTM(units=80, return_sequences=True, activation='tanh')(encoder_input)\n",
    "encoder_x = Dropout(0.5)(encoder_x)\n",
    "encoder_x = LSTM(units=40, return_sequences=False, activation='tanh')(encoder_x)\n",
    "\n",
    "encoder_y = Conv1D(filters=40,kernel_size=3,activation='tanh')(encoder_input)\n",
    "encoder_y = GlobalMaxPool1D()(encoder_y)\n",
    "\n",
    "encoded = concatenate([encoder_x,encoder_y])\n",
    "encoded = Dropout(0.5)(encoded)\n",
    "encoded = Dense(80, activation='tanh')(encoded)#Relu and selu\n",
    "encoded = Dropout(0.5)(encoded)\n",
    "encoded = Dense(40, activation='tanh')(encoded)#Relu and selu\n",
    "predictions = Dense(1, activation='sigmoid')(encoded)#Relu and selu\n",
    "predictor = Model(encoder_input,predictions)\n",
    "\n",
    "predictor.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "#print(predictor.summary())\n",
    "\n",
    "checkpoint_name = 'TEDS_Predictor_Weights.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot it as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(predictor, show_shapes=True, to_file='TEDS.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictor.fit(LSTM_x_train, temp_LSTM_y_train, epochs=250, batch_size=512, shuffle=True, validation_split=0.33, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our weights, and we measure the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wights_file = 'TEDS_Predictor_Weights.hdf5' # choose the best checkpoint few features\n",
    "predictor.load_weights(wights_file) # load it\n",
    "predictor.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 13.686472375760749 456.94272182388676 21.37621860441848\n",
      "0.861136439080712\n",
      "Test: 22.81737622261625 1048.122686165827 32.37472295118256\n",
      "0.6154013922038681\n"
     ]
    }
   ],
   "source": [
    "temp_pred = target_scaler.inverse_transform(predictor.predict(LSTM_x_train))\n",
    "predictions = [i[0] for i in temp_pred]\n",
    "print('Train:',mean_absolute_error(LSTM_y_train,predictions),mean_squared_error(LSTM_y_train,predictions),sqrt(mean_squared_error(LSTM_y_train,predictions)))\n",
    "print(r2_score(LSTM_y_train,predictions))\n",
    "temp_pred = target_scaler.inverse_transform(predictor.predict(LSTM_x_test))\n",
    "predictions = [i[0] for i in temp_pred]\n",
    "print('Test:',mean_absolute_error(LSTM_y_test,predictions),mean_squared_error(LSTM_y_test,predictions),sqrt(mean_squared_error(LSTM_y_test,predictions)))\n",
    "print(r2_score(LSTM_y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
