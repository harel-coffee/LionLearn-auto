{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LioNets: Turbofan Engine Degradation Simulation Dataset with Neural Networks -> Classification Task\n",
    "\n",
    "In this notebook, we present how LioNets can be applied in predictive models using time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from IPython.display import SVG\n",
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from math import sqrt, exp, log\n",
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score, balanced_accuracy_score, accuracy_score\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, TimeDistributed, RepeatVector,Flatten, Input, Dropout, LSTM, concatenate, Reshape, Conv1D, GlobalMaxPool1D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from lionets import LioNets\n",
    "from altruist.altruist import Altruist\n",
    "from utilities.evaluation import Evaluation\n",
    "from utilities.load_dataset import Load_Dataset\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from innvestigate.utils.keras import checks\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load and clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm, feature_names = Load_Dataset.load_data_turbofan(False)\n",
    "\n",
    "fm1_train = fm['FaultMode1']['df_train']\n",
    "fm1_train_target = fm1_train['RUL'].values\n",
    "fm1_test= fm['FaultMode1']['df_test']\n",
    "fm1_test_target = fm1_test['RUL'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dropping some unecessary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_train = fm1_train.drop(columns=['t', 'os_1', 'os_2', 'os_3', 's_01', 's_05', 's_06', 's_10', 's_16', 's_18', 's_19', 's_22', 's_23', 's_24', 's_25', 's_26'])\n",
    "LSTM_test = fm1_test.drop(columns=['t', 'os_1', 'os_2', 'os_3', 's_01', 's_05', 's_06', 's_10', 's_16', 's_18', 's_19', 's_22', 's_23', 's_24', 's_25', 's_26'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We collect the different units, in order to the next steps to create time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_units = set(LSTM_train['u'].values)\n",
    "test_units = set(LSTM_test['u'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are scaling our data per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['s_02', 's_03', 's_04', 's_07', 's_08', 's_09', 's_11', 's_12',\n",
    "            's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n",
    "scalers = {}\n",
    "for column in sensors:\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    LSTM_train[column] = scaler.fit_transform(LSTM_train[column].values.reshape(-1,1))\n",
    "    LSTM_test[column] = scaler.transform(LSTM_test[column].values.reshape(-1,1))\n",
    "    scalers[column] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create time windows with a specific size. In this example, we create time windows of 50 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_scalers = {}\n",
    "window = 50\n",
    "temp_LSTM_x_train = []\n",
    "LSTM_y_train = []\n",
    "for unit in train_units:\n",
    "    temp_unit = LSTM_train[LSTM_train['u']==unit].drop(columns=['u','RUL']).values\n",
    "    temp_unit_RUL = LSTM_train[LSTM_train['u']==unit]['RUL'].values\n",
    "    \n",
    "    for i in range(len(temp_unit) - window + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = []\n",
    "        for j in range(window):\n",
    "            temp_instance.append(temp_unit[i+j])\n",
    "        temp_LSTM_x_train.append(np.array(temp_instance))\n",
    "        LSTM_y_train.append(temp_unit_RUL[i+window-1])\n",
    "LSTM_y_train = np.array(LSTM_y_train)\n",
    "LSTM_x_train = np.array(temp_LSTM_x_train)\n",
    "\n",
    "temp_LSTM_x_test = []\n",
    "LSTM_y_test = []\n",
    "for unit in test_units:\n",
    "    temp_unit = LSTM_test[LSTM_test['u']==unit].drop(columns=['u','RUL']).values\n",
    "    temp_unit_RUL = LSTM_test[LSTM_test['u']==unit]['RUL'].values\n",
    "        \n",
    "    for i in range(len(temp_unit) - window + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = []\n",
    "        for j in range(window):\n",
    "            temp_instance.append(temp_unit[i+j])\n",
    "        temp_LSTM_x_test.append(np.array(temp_instance))\n",
    "        LSTM_y_test.append(temp_unit_RUL[i+window-1])\n",
    "LSTM_y_test = np.array(LSTM_y_test)\n",
    "LSTM_x_test = np.array(temp_LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many train, test instances we have. These are changing regarding the time window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_x_train.shape, LSTM_x_test.shape, LSTM_y_train.shape, LSTM_y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to transform our RUL to binary classes. 0 Would mean that no maintenance is needed, because the prediction had a high RUL value. 1 would mean that the RUL is low and you may need maintenance on your component! You can try different time frames as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frame = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_LSTM_y_train = np.array([1 if i <= time_frame else 0 for i in LSTM_y_train])\n",
    "temp_LSTM_y_test = np.array([1 if i <= time_frame else 0 for i in LSTM_y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We need a rmse loss function too! for the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build our predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = fm1_train.columns\n",
    "encoder_input = Input(shape=(LSTM_x_train[0].shape))\n",
    "\n",
    "encoder_x = LSTM(units=80, return_sequences=True, activation='tanh')(encoder_input)\n",
    "encoder_x = Dropout(0.7)(encoder_x)\n",
    "encoder_x = LSTM(units=40, return_sequences=False, activation='tanh')(encoder_x)\n",
    "\n",
    "encoder_y = Conv1D(filters=40,kernel_size=3,activation='tanh')(encoder_input)\n",
    "encoder_y = GlobalMaxPool1D()(encoder_y)\n",
    "\n",
    "encoded = concatenate([encoder_x,encoder_y])\n",
    "encoded = Dropout(0.7)(encoded)\n",
    "encoded = Dense(80, activation='tanh')(encoded)#Relu and selu\n",
    "encoded = Dropout(0.7)(encoded)\n",
    "encoded = Dense(40, activation='tanh')(encoded)#Relu and selu\n",
    "predictions = Dense(1, activation='sigmoid')(encoded)#Relu and selu\n",
    "predictor = Model(encoder_input,predictions)\n",
    "\n",
    "predictor.compile(optimizer=\"adam\",loss=['binary_crossentropy'],metrics=['accuracy'])\n",
    "#print(predictor.summary())\n",
    "\n",
    "checkpoint_name = 'TEDS_Predictor_Classification.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictor.fit(LSTM_x_train, temp_LSTM_y_train, epochs=250, batch_size=512, shuffle=True, validation_split=0.33, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our weights, and we measure the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'weights/TEDS_Predictor_Classification.hdf5' # choose the best checkpoint few features\n",
    "predictor.load_weights(weights_file) # load it\n",
    "predictor.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pred = predictor.predict(LSTM_x_train)\n",
    "predictions = [0 if i[0] <=0.5 else 1 for i in temp_pred]\n",
    "print('Train:',f1_score(temp_LSTM_y_train,predictions, average='micro'),f1_score(temp_LSTM_y_train,predictions, average='weighted'),balanced_accuracy_score(temp_LSTM_y_train,predictions),accuracy_score(temp_LSTM_y_train,predictions))\n",
    "\n",
    "temp_pred = predictor.predict(LSTM_x_test)\n",
    "predictions = [0 if i[0] <=0.5 else 1 for i in temp_pred]\n",
    "print('Test:',f1_score(temp_LSTM_y_test,predictions, average='micro'),f1_score(temp_LSTM_y_test,predictions, average='weighted'),balanced_accuracy_score(temp_LSTM_y_test,predictions),accuracy_score(temp_LSTM_y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have to extract the encoder from our predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input=predictor.input, output=[predictor.layers[-2].output])\n",
    "encoder.trainable = False\n",
    "encoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "#encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to extract for all instances, their encoded representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_LSTM_x_train = encoder.predict(LSTM_x_train)\n",
    "encoded_LSTM_x_test = encoder.predict(LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by that, we build the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoded_LSTM_x_train[0].shape))\n",
    "decoded = Dense(120, activation='tanh')(encoded_input)\n",
    "decoded = Dropout(0.5)(decoded)\n",
    "\n",
    "decoded_y = RepeatVector(54)(decoded)\n",
    "decoded_y = Conv1D(filters=50,kernel_size=5,activation='tanh')(decoded_y)\n",
    "\n",
    "decoded_x = RepeatVector(50)(decoded)\n",
    "decoded_x = LSTM(units=80, return_sequences=True, activation='tanh')(decoded_x)\n",
    "decoded_x = Dropout(0.5)(decoded_x)\n",
    "decoded_x = LSTM(units=50, return_sequences=True, activation='tanh')(decoded_x)\n",
    "\n",
    "decoded = concatenate([decoded_x,decoded_y])\n",
    "decoded = LSTM(50, return_sequences=True, activation='sigmoid')(decoded)\n",
    "decoded = Dropout(0.5)(decoded)\n",
    "decoded = LSTM(14, return_sequences=True, activation='sigmoid')(decoded)\n",
    "\n",
    "decoder = Model(encoded_input,decoded)\n",
    "\n",
    "decoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "#print(decoder.summary())\n",
    "\n",
    "checkpoint_name = 'TEDS_Decoder_Classification.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder.fit(encoded_LSTM_x_train, LSTM_x_train, epochs=500, batch_size=512, shuffle=True, validation_split=0.33, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'weights/TEDS_Decoder_Classification.hdf5' # choose the best checkpoint few features\n",
    "decoder.load_weights(weights_file) # load it\n",
    "decoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.evaluate(encoded_LSTM_x_train,LSTM_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.evaluate(encoded_LSTM_x_test,LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LioNets Experiments\n",
    "Having everything setted up, we are now ready to try our methodology. We first initialize LioNets. LioNets requires a predictor (the classifier itself), an encoder (extracted from the predictor), a decoder, as well as some data (for best results the training data, in order to push the neighbourhood generation through known distribution for the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lionet = LioNets(predictor, decoder, encoder, LSTM_x_train, double_detector=False)\n",
    "transparent_model = Ridge(alpha=100,fit_intercept=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7777)\n",
    "train = np.array(random.sample(LSTM_x_train.tolist(),200))\n",
    "valid = np.array(random.sample(LSTM_x_test.tolist(),200))\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the fidelity of Lime and LioNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_predict(instance):\n",
    "    t_instance = np.array([instance]).reshape((len(instance),50,14))\n",
    "    a = predictor.predict(t_instance)\n",
    "    b = 1 - a \n",
    "    return np.column_stack((b,a))\n",
    "explainer = LimeTabularExplainer(training_data=train.reshape(((len(train), 700))), \n",
    "                 discretize_continuous=False,\n",
    "                 mode=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_lime(instance):\n",
    "    t_instance = instance.reshape((700))\n",
    "    explanation = explainer.explain_instance(t_instance, predict_fn=lime_predict, num_features=700)\n",
    "    local_pred = explanation.local_pred[0]\n",
    "    return local_pred #This is because lime interprets class with label 1\n",
    "def fi_lionets(instance):\n",
    "    weights, res, loc_res = lionet.explain_instance(instance,3000,transparent_model)\n",
    "    return loc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluation(predictor.predict,None,lambda x: x,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity = evaluator.fidelity(train, [fi_lime, fi_lionets], class_n=0)\n",
    "print(\"Train:\")\n",
    "print('  Lime fidelity:', fidelity[0][0])\n",
    "print('  LioNets fidelity:', fidelity[1][0])\n",
    "fidelity = evaluator.fidelity(valid, [fi_lime, fi_lionets], class_n=0)\n",
    "print(\"Valid:\")\n",
    "print('  Lime fidelity:', fidelity[0][0])\n",
    "print('  LioNets fidelity:', fidelity[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate non zero weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = iutils.to_list(predictor.outputs)\n",
    "softmax_found = False\n",
    "ret = []\n",
    "for x in Xs:\n",
    "    layer, node_index, tensor_index = x._keras_history\n",
    "    if checks.contains_activation(layer, activation=\"sigmoid\"):\n",
    "        softmax_found = True\n",
    "        if isinstance(layer, keras.layers.Activation):\n",
    "            ret.append(layer.get_input_at(node_index))\n",
    "        else:\n",
    "            layer_wo_act = innvestigate.utils.keras.graph.copy_layer_wo_activation(layer)\n",
    "            ret.append(layer_wo_act(layer.get_input_at(node_index)))\n",
    "model2 = Model(input=predictor.input, output=ret)\n",
    "model2.trainable = False\n",
    "model2.compile(optimizer=\"adam\",loss=['binary_crossentropy'],metrics=['accuracy'])\n",
    "analyzer = innvestigate.create_analyzer('input_t_gradient',model2) #, low=0, high=1 on deep taylor bounded\n",
    "analyzerLRP = innvestigate.create_analyzer('lrp.epsilon',model2) #, low=0, high=1 on deep taylor bounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_GxI(instance):\n",
    "    ooo = analyzer.analyze(np.array([instance]))[0]\n",
    "    return [ooo][0].reshape((700))\n",
    "def fi_LRP(instance):\n",
    "    ooo = analyzerLRP.analyze(np.array([instance]))[0]\n",
    "    ooo = ooo*instance #only on lrp\n",
    "    return [ooo][0].reshape((700))\n",
    "def fi_lime(instance):\n",
    "    t_instance = instance.reshape((700))\n",
    "    explanation = explainer.explain_instance(t_instance, predict_fn=lime_predict, num_features=700)\n",
    "    weights = OrderedDict(explanation.as_list())\n",
    "    lime_w = dict(sorted(zip(list([int(wk) for wk in weights.keys()]), list(weights.values()))))\n",
    "    return np.array([lime_w[o] for o in lime_w.keys()]) #This is because lime interprets class with label 1\n",
    "def fi_lionets(instance):\n",
    "    weights, res, loc_res = lionet.explain_instance(instance,3000,transparent_model)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero = evaluator.non_zero_weights(train, [fi_GxI, fi_LRP, fi_lime, fi_lionets])\n",
    "print(\"Train:\")\n",
    "print('  GxI Non Zero:', non_zero[0][0])\n",
    "print('  LRP Non Zero:', non_zero[1][0])\n",
    "print('  Lime Non Zero:', non_zero[2][0])\n",
    "print('  LioNets Non Zero:', non_zero[3][0])\n",
    "non_zero = evaluator.non_zero_weights(valid, [fi_GxI, fi_LRP, fi_lime, fi_lionets])\n",
    "print(\"Valid:\")\n",
    "print('  GxI Non Zero:', non_zero[0][0])\n",
    "print('  LRP Non Zero:', non_zero[1][0])\n",
    "print('  Lime Non Zero:', non_zero[2][0])\n",
    "print('  LioNets Non Zero:', non_zero[3][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness = evaluator.robustness(train,[fi_lime, fi_GxI, fi_LRP, fi_lionets],None, [700,[50,14]])\n",
    "print(\"Train\")\n",
    "print('  Lime Robustness:', robustness[0])\n",
    "print('  GxI Robustness:', robustness[1])\n",
    "print('  LRP Robustness:', robustness[2])\n",
    "print('  LioNets Robustness:', robustness[3])\n",
    "robustness = evaluator.robustness(valid,[fi_lime, fi_GxI, fi_LRP, fi_lionets],None, [700,[50,14]])\n",
    "print(\"Valid:\")\n",
    "print('  Lime Robustness:', robustness[0])\n",
    "print('  GxI Robustness:', robustness[1])\n",
    "print('  LRP Robustness:', robustness[2])\n",
    "print('  LioNets Robustness:', robustness[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altruist Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_GxI(instance, prediction, model):\n",
    "    ooo = analyzer.analyze(np.array([instance.reshape((50,14))]))[0]    \n",
    "    weights = []\n",
    "    for i in range(14):\n",
    "        weights.append(ooo[:,i:i+1].mean())\n",
    "    return np.array(weights)\n",
    "def fi_LRP(instance, prediction, model):\n",
    "    ooo = analyzerLRP.analyze(np.array([instance.reshape((50,14))]))[0]\n",
    "    ooo = ooo*instance.reshape((50,14)) #only on lrp\n",
    "    weights = []\n",
    "    for i in range(14):\n",
    "        weights.append(ooo[:,i:i+1].mean())\n",
    "    return np.array(weights)\n",
    "def fi_lime(instance, prediction, model):\n",
    "    explanation = explainer.explain_instance(instance, predict_fn=lime_predict, num_features=700)\n",
    "    weights = OrderedDict(explanation.as_list())\n",
    "    lime_w = dict(sorted(zip(list([int(wk) for wk in weights.keys()]), list(weights.values()))))\n",
    "    lweights = np.array([lime_w[o] for o in lime_w.keys()]).reshape((50,14))\n",
    "    weights = []\n",
    "    for i in range(14):\n",
    "        weights.append(lweights[:,i:i+1].mean())\n",
    "    return np.array(weights)\n",
    "def fi_lionets(instance, prediction, model):\n",
    "    weights, res, loc_res = lionet.explain_instance(instance.reshape((50,14)),3000,transparent_model)\n",
    "    lweights = weights.reshape((50,14))\n",
    "    weights = []\n",
    "    for i in range(14):\n",
    "        weights.append(lweights[:,i:i+1].mean())\n",
    "    return np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"*Please let it run, it will take time probably*\")\n",
    "fi_names = {fi_GxI:'GxI',fi_LRP:'LRP',fi_lime:'Lime',fi_lionets:'LioNets'}\n",
    "fis = [fi_GxI, fi_LRP, fi_lime,fi_lionets]\n",
    "fis_scores = []\n",
    "for i in fis:\n",
    "    fis_scores.append([])\n",
    "count = 0\n",
    "feature_names = [i for i in range(14)]\n",
    "X_t = np.array([inst.reshape((700)) for inst in train])\n",
    "altruistino = Altruist(predictor, X_t, fis, feature_names, None, True,[50,14])\n",
    "for instance in X_t:\n",
    "    if (count + 1) % 50 == 0:\n",
    "        print(count+1,\"/\",len(train),\"..\",end=\", \")\n",
    "    #print(len(instance))\n",
    "    count = count + 1\n",
    "    untruthful_features = altruistino.find_untruthful_features(instance)\n",
    "    for i in range(len(untruthful_features[0])):\n",
    "        fis_scores[i].append(len(untruthful_features[0][i]))\n",
    "count = 0\n",
    "print()\n",
    "print(\"Train:\")\n",
    "for fis_score in fis_scores:\n",
    "    fi = fis[count]\n",
    "    count = count + 1\n",
    "    print(' ',fi_names[fi],np.array(fis_score).mean())\n",
    "fi_matrix = np.array(fis_scores)\n",
    "count = 0\n",
    "fi_all = []\n",
    "for instance in X_t:\n",
    "    fi_all.append(fi_matrix[:,count].min())\n",
    "    count = count + 1\n",
    "print(\"Altogether:\",np.array(fi_all).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*Please let it run, it will take time probably*\")\n",
    "fi_names = {fi_GxI:'GxI',fi_LRP:'LRP',fi_lime:'Lime',fi_lionets:'LioNets'}\n",
    "fis = [fi_GxI, fi_LRP, fi_lime,fi_lionets]\n",
    "fis_scores = []\n",
    "for i in fis:\n",
    "    fis_scores.append([])\n",
    "count = 0\n",
    "feature_names = [i for i in range(14)]\n",
    "X_v = np.array([inst.reshape((700)) for inst in valid])\n",
    "for instance in X_v:\n",
    "    if (count + 1) % 50 == 0:\n",
    "        print(count+1,\"/\",len(train),\"..\",end=\", \")\n",
    "    #print(len(instance))\n",
    "    count = count + 1\n",
    "    altruistino = Altruist(predictor, X_t, fis, feature_names, None, True,[50,14])\n",
    "    untruthful_features = altruistino.find_untruthful_features(instance)\n",
    "    for i in range(len(untruthful_features[0])):\n",
    "        fis_scores[i].append(len(untruthful_features[0][i]))\n",
    "count = 0\n",
    "print()\n",
    "print(\"Valid:\")\n",
    "for fis_score in fis_scores:\n",
    "    fi = fis[count]\n",
    "    count = count + 1\n",
    "    print(' ',fi_names[fi],np.array(fis_score).mean())\n",
    "fi_matrix = np.array(fis_scores)\n",
    "count = 0\n",
    "fi_all = []\n",
    "for instance in X_t:\n",
    "    fi_all.append(fi_matrix[:,count].min())\n",
    "    count = count + 1\n",
    "print(\"Altogether:\",np.array(fi_all).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we would like to manually evaluate an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_instance = LSTM_x_train[112].copy()\n",
    "model = Ridge(alpha=100,fit_intercept=True,random_state=0)\n",
    "weights, real_prediction, local_prediction = lionet.explain_instance(temp_instance,3000,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Real prediction: \" + str(real_prediction)[:7] + \", Local prediction: \" + str(local_prediction)[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we would like is to change the class. Currently, the classifier for the predictor is closer to the maintenance class. So we need to see which measurements are pussing the prediction towards this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From LioNets we acquired the weights of each sensor's measurements. Then we extract some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_all = {}\n",
    "count = 0\n",
    "for j in range(50):\n",
    "    count2 = 0\n",
    "    for i in sensors:\n",
    "        sensors_all.setdefault(i,[]).append([j, weights[count+count2], temp_instance[j][count2],\n",
    "                                             weights[count+count2]*temp_instance[j][count2]])\n",
    "        count2 = count2 + 1\n",
    "    count = count + 14\n",
    "sensors_std = []\n",
    "sensors_mean = []\n",
    "sensors_max = []\n",
    "sensors_min = []\n",
    "for i in sensors_all:\n",
    "    naa = np.array(sensors_all[i])[:,3]\n",
    "    sensors_std.append(naa.std())\n",
    "    sensors_mean.append(naa.mean())\n",
    "    sensors_max.append(naa.max())\n",
    "    sensors_min.append(naa.min())\n",
    "    #print(i, naa.mean(), naa.std(), naa.max(), naa.min())\n",
    "statistics = pd.DataFrame({\"Sensor\": list(sensors), \"Mean\": list(sensors_mean), \"STD\": list(sensors_std), \n",
    "                           \"Max\": list(sensors_max), \"Min\": list(sensors_min), \n",
    "                           \"Max-Min\": np.array(sensors_max) + np.array(sensors_min)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_vis = [i[2:] for i in sensors]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4), dpi=220)\n",
    "sns.barplot(to_vis,sensors_mean,ax=axs[0])\n",
    "axs[0].set_title('Mean')\n",
    "sns.barplot(to_vis,sensors_std,ax=axs[1])\n",
    "axs[1].set_title('STD')\n",
    "sns.barplot(to_vis,sensors_max,ax=axs[2])\n",
    "sns.barplot(to_vis,sensors_min,ax=axs[2])\n",
    "axs[2].set_title('Max and Min')\n",
    "fig.suptitle('Sensor Importance Statistics')\n",
    "plt.show()\n",
    "\n",
    "def plot_sensor(sens_i=1):\n",
    "    plt.figure(figsize=(14, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "    plt.subplot(131)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,1])\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,1].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence\"))\n",
    "    plt.subplot(132)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,2],color='g')\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,2].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" value\"))\n",
    "    plt.subplot(133)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,3],color='r')\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,3].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence * value\"))\n",
    "    plt.show()\n",
    "inter=interactive(plot_sensor \n",
    "   , sens_i=(1,14))\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the measurements from the s_12 sensor (number 8) with negative influence, which seems to influence a lot the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = 3-1\n",
    "for i in range(40,50):\n",
    "    #print(weights.reshape(50,14)[i:i+1,sens:sens+1][0])\n",
    "    if weights.reshape(50,14)[i:i+1,sens:sens+1][0] > 0.001:\n",
    "        temp_instance[i:i+1,sens:sens+1][0]=temp_instance[i:i+1,sens:sens+1][0]-0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the modified instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, real_prediction, local_prediction = lionet.explain_instance(temp_instance,3000,model)\n",
    "weights = weights #* temp_instance.reshape(700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Real prediction: \" + str(real_prediction)[:7] + \", Local prediction: \" + str(local_prediction)[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to lower the probability. Now the predictor is predicting with stronger confidence (close to 90%) that no maintenance is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the probability to maintenance increased correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_all = {}\n",
    "count = 0\n",
    "for j in range(50):\n",
    "    count2 = 0\n",
    "    for i in sensors:\n",
    "        sensors_all.setdefault(i,[]).append([j, weights[count+count2], temp_instance[j][count2],\n",
    "                                             weights[count+count2]*temp_instance[j][count2]])\n",
    "        count2 = count2 + 1\n",
    "    count = count + 14\n",
    "sensors_std = []\n",
    "sensors_mean = []\n",
    "sensors_max = []\n",
    "sensors_min = []\n",
    "for i in sensors_all:\n",
    "    naa = np.array(sensors_all[i])[:,3]\n",
    "    sensors_std.append(naa.std())\n",
    "    sensors_mean.append(naa.mean())\n",
    "    sensors_max.append(naa.max())\n",
    "    sensors_min.append(naa.min())\n",
    "    #print(i, naa.mean(), naa.std(), naa.max(), naa.min())\n",
    "statistics = pd.DataFrame({\"Sensor\": list(sensors), \"Mean\": list(sensors_mean), \"STD\": list(sensors_std), \n",
    "                           \"Max\": list(sensors_max), \"Min\": list(sensors_min), \n",
    "                           \"Max-Min\": np.array(sensors_max) + np.array(sensors_min)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vis = [i[2:] for i in sensors]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4), dpi=200)\n",
    "sns.barplot(to_vis,sensors_mean,ax=axs[0])\n",
    "axs[0].set_title('Mean')\n",
    "sns.barplot(to_vis,sensors_std,ax=axs[1])\n",
    "axs[1].set_title('STD')\n",
    "sns.barplot(to_vis,sensors_max,ax=axs[2])\n",
    "sns.barplot(to_vis,sensors_min,ax=axs[2])\n",
    "axs[2].set_title('Max and Min')\n",
    "fig.suptitle('Sensor Importance Statistics')\n",
    "plt.show()\n",
    "\n",
    "def plot_sensor(sens_i=1):\n",
    "    plt.figure(figsize=(14, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "    plt.subplot(131)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,1])\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,1].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence\"))\n",
    "    plt.subplot(132)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,2],color='g')\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,2].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" value\"))\n",
    "    plt.subplot(133)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,3],color='r')\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,3].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence * value\"))\n",
    "    plt.show()\n",
    "inter=interactive(plot_sensor \n",
    "   , sens_i=(1,14))\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try for another instance, and play with the plots :) Thanks for using LioNets.\n",
    "\n",
    "For any question contact us at GitHub repo: https://github.com/intelligence-csd-auth-gr/LionLearn.git\n",
    "\n",
    "or at our lab's website: https://intelligence.csd.auth.gr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
